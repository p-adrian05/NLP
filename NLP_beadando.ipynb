{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd0d255ca7a4e53a8a881991228f4120f58f8f5b42582956d513293a0a546c2c96b",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/rogate16/amazon-reviews-2018-full-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   rating                                         reviewText\n",
       "0     5.0           super smooth and yummy with crunchy bits\n",
       "1     5.0                               Perfect for kombucha\n",
       "2     5.0  Finally a harness that fits my puppy. I really...\n",
       "3     5.0  I LOVE THEM!! I bought them at Micheals our of...\n",
       "4     5.0  I love this pen! I love the shape of it, the f..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>super smooth and yummy with crunchy bits</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>Perfect for kombucha</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>I love this pen! I love the shape of it, the f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./amazon_reviews.csv\")\n",
    "\n",
    "df.drop(df.iloc[:, 1:9], inplace = True, axis = 1)\n",
    "df.drop(['userName', 'reviewTime','summary','vote'], axis = 1,inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_train, df_validate, df_test = np.split(df.sample(frac=0.4, random_state=200), \n",
    "                       [int(.2*len(df)), int(.3*len(df))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1102318\n220462\n110232\n110234\n"
     ]
    }
   ],
   "source": [
    "print(df.size)\n",
    "print(df_train.size)\n",
    "print(df_validate.size)\n",
    "print(df_test.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['my', 'dog', 'love', 'it', 'smell', 'aw']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import PorterStemmer  \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "\n",
    "def is_html_tag(word):\n",
    "    w = word.replace(\"\\n\", \"\")\n",
    "    return w.startswith(\"<\") or w.startswith(\">\") or w.startswith(\"/\") or w.strip()[:2] == \"br\"\n",
    "\n",
    "def remove_html_tags(sentence):\n",
    "    single_spaces = \" \".join(sentence.split())\n",
    "\n",
    "    return \" \".join([token for token in single_spaces.split(\" \") if not is_html_tag(token)])\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    return word_tokenize(sentence.lower())\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    return \" \".join([word for word in sentence.split(\" \") if not word in STOPWORDS])\n",
    "\n",
    "def remove_punctuation(tokenized_sentence):\n",
    "    return [stemmer.stem(w_n_lemmatizer.lemmatize(w)) for w in tokenized_sentence if w.isalpha()]\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return remove_punctuation(tokenize_sentence(remove_stopwords(remove_html_tags(str(sentence)))))\n",
    "\n",
    "print(preprocess(df_train[\"reviewText\"].values[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        rating                                         reviewText\n517892     5.0  Great adapter to convert your small tanks to y...\n299317     4.0              My dog loves it, but it smells awful.\n262608     5.0  I was glad to find these refills online.  I lo...\n148619     5.0  These worked fantastically. I'd never used thi...\n488257     5.0                                              Yummy\n...        ...                                                ...\n416233     5.0  My cats love this food! Such a reasonable pric...\n239020     5.0                           Dog unable to rip apart!\n533511     5.0  I used this chord to,go,from my Bass peddle to...\n8272       5.0  I've outsourced most of my lawn maintenance, b...\n345317     3.0                      not enough, packets are small\n\n[110231 rows x 2 columns]\n110231\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(value):\n",
    "    if( value<3.0 ):\n",
    "        return \"negative\"\n",
    "    elif (value == 3.0):\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "df_train[\"sentiment\"] = [None] * len(df_train)\n",
    "df_train[\"sentiment\"] = df_train[\"rating\"].apply(sentiment)\n",
    "df_validate[\"sentiment\"] = [None] * len(df_validate)\n",
    "df_validate[\"sentiment\"] = df_validate[\"rating\"].apply(sentiment)\n",
    "df_test[\"sentiment\"] = [None] * len(df_test)\n",
    "df_test[\"sentiment\"] = df_test[\"rating\"].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        rating                                         reviewText sentiment\n",
       "517892     5.0     [great, adapt, convert, small, tank, big, one]  positive\n",
       "299317     4.0                     [my, dog, love, it, smell, aw]  positive\n",
       "262608     5.0  [i, glad, find, refil, onlin, i, love, paper, ...  positive\n",
       "148619     5.0  [these, work, fantast, i, never, use, type, to...  positive\n",
       "488257     5.0                                            [yummi]  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>reviewText</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>517892</th>\n      <td>5.0</td>\n      <td>[great, adapt, convert, small, tank, big, one]</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>299317</th>\n      <td>4.0</td>\n      <td>[my, dog, love, it, smell, aw]</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>262608</th>\n      <td>5.0</td>\n      <td>[i, glad, find, refil, onlin, i, love, paper, ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>148619</th>\n      <td>5.0</td>\n      <td>[these, work, fantast, i, never, use, type, to...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>488257</th>\n      <td>5.0</td>\n      <td>[yummi]</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "df_train[\"reviewText\"] = df_train[\"reviewText\"].apply(preprocess)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_input, vocab_size):\n",
    "    d = dict()\n",
    "\n",
    "    for tokens in tokenized_input:\n",
    "        for token in tokens:\n",
    "            # double check\n",
    "            if token not in STOPWORDS and token.isalpha():\n",
    "                d[token] = d.get(token, 0) + 1\n",
    "\n",
    "\n",
    "\n",
    "    return {k for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)[:vocab_size]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 4000\n",
    "VOCAB = build_vocab(df_train[\"reviewText\"], VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "metadata": {},
     "execution_count": 247
    }
   ],
   "source": [
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies_for_sentiment(df):\n",
    "    dict_freqs = {\"positive\": {}, \"negative\": {},\"neutral\":{}}\n",
    "    \n",
    "    for idx in range(df.shape[0]):\n",
    "        tokens = df_train.iloc[idx][\"reviewText\"]\n",
    "        sentiment = df_train.iloc[idx][\"sentiment\"]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in VOCAB:\n",
    "                dict_freqs[sentiment][token] = dict_freqs[sentiment].get(token, 0) + 1\n",
    "            \n",
    "    return dict_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table = get_frequencies_for_sentiment(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21124"
      ]
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "frequency_table[\"positive\"][\"love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(frequency_table, tweet_tokens):\n",
    "    positives = 0\n",
    "    negatives = 0\n",
    "    neutrals = 0\n",
    "\n",
    "    for t in set(tweet_tokens):\n",
    "        positives += frequency_table[\"positive\"].get(t, 0)\n",
    "        negatives += frequency_table[\"negative\"].get(t, 0)\n",
    "        neutrals += frequency_table[\"neutral\"].get(t, 0)\n",
    "    \n",
    "    return pd.Series({\"positives\": positives, \"negatives\": negatives,\"neutrals\": neutrals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        positives  negatives  neutrals\n",
       "517892      43357       4593      3572\n",
       "299317      36134       3740      2463\n",
       "262608      34790       2920      2460\n",
       "148619     100284      15175     10514\n",
       "488257        554          9        11\n",
       "...           ...        ...       ...\n",
       "416233      46425       4184      3068\n",
       "239020      13780       2797      1692\n",
       "533511      33821       5283      3819\n",
       "8272       288096      45760     34325\n",
       "345317       6388       1229      1049\n",
       "\n",
       "[110231 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>positives</th>\n      <th>negatives</th>\n      <th>neutrals</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>517892</th>\n      <td>43357</td>\n      <td>4593</td>\n      <td>3572</td>\n    </tr>\n    <tr>\n      <th>299317</th>\n      <td>36134</td>\n      <td>3740</td>\n      <td>2463</td>\n    </tr>\n    <tr>\n      <th>262608</th>\n      <td>34790</td>\n      <td>2920</td>\n      <td>2460</td>\n    </tr>\n    <tr>\n      <th>148619</th>\n      <td>100284</td>\n      <td>15175</td>\n      <td>10514</td>\n    </tr>\n    <tr>\n      <th>488257</th>\n      <td>554</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>416233</th>\n      <td>46425</td>\n      <td>4184</td>\n      <td>3068</td>\n    </tr>\n    <tr>\n      <th>239020</th>\n      <td>13780</td>\n      <td>2797</td>\n      <td>1692</td>\n    </tr>\n    <tr>\n      <th>533511</th>\n      <td>33821</td>\n      <td>5283</td>\n      <td>3819</td>\n    </tr>\n    <tr>\n      <th>8272</th>\n      <td>288096</td>\n      <td>45760</td>\n      <td>34325</td>\n    </tr>\n    <tr>\n      <th>345317</th>\n      <td>6388</td>\n      <td>1229</td>\n      <td>1049</td>\n    </tr>\n  </tbody>\n</table>\n<p>110231 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 254
    }
   ],
   "source": [
    "X_train_logistic = df_train[\"reviewText\"].apply(lambda tokens: extract_features(frequency_table, tokens))\n",
    "\n",
    "X_train_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_logistic = scaler.fit_transform(X_train_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_logistic = df_train[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\adria\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_logistic, y_train_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 0.6959385290889133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds_train = clf.predict(X_train_logistic)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_train_logistic, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate[\"reviewText\"] = df_validate[\"reviewText\"].apply(preprocess)\n",
    "X_val_logistic = df_validate[\"reviewText\"].apply(lambda tokens: extract_features(frequency_table, tokens))\n",
    "X_val_logistic = scaler.transform(X_val_logistic)\n",
    "y_val_logistic = df_validate[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation accuracy: 0.6964765222439945\n"
     ]
    }
   ],
   "source": [
    "preds_val = clf.predict(X_val_logistic)\n",
    "\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val_logistic, preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"reviewText\"] = df_test[\"reviewText\"].apply(preprocess)\n",
    "X_test_logistic = df_test[\"reviewText\"].apply(lambda tokens: extract_features(frequency_table, tokens))\n",
    "X_test_logistic = scaler.transform(X_test_logistic)\n",
    "y_test_logistic = df_test[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test accuracy: 0.6944862746521037\n"
     ]
    }
   ],
   "source": [
    "preds_test = clf.predict(X_test_logistic)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(y_test_logistic, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}